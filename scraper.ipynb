{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4 as bs\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEADERS = ({\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36 Edg/109.0.1518.78\",})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get universities with their links\n",
    "def getUniversities():\n",
    "  with open(\"./data/universities.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Name\", \"Link\"])\n",
    "    providerURL = \"https://www.classcentral.com/universities\"\n",
    "    providerPage = requests.get(providerURL, headers=HEADERS)\n",
    "\n",
    "    soup = bs(providerPage.content, \"lxml\")\n",
    "    providerList = soup.find_all(attrs={ \"class\" : \"row vert-align-middle color-charcoal hover-bg-blue-xlight padding-vert-small padding-horz-medium nowrap\" })\n",
    "    for i in providerList:\n",
    "      try:\n",
    "        linkProviders = [str(i.text.strip()), str(i.get(\"href\"))]\n",
    "        writer.writerow(linkProviders)\n",
    "        print(linkProviders)\n",
    "      except:\n",
    "        print(\"Error\")\n",
    "\n",
    "# getUniversities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get institution with their links\n",
    "def getInstitutions():\n",
    "  with open(\"./data/institution.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Name\", \"Link\"])\n",
    "    providerURL = \"https://www.classcentral.com/institutions\"\n",
    "    providerPage = requests.get(providerURL, headers=HEADERS)\n",
    "\n",
    "    soup = bs(providerPage.content, \"lxml\")\n",
    "    providerList = soup.find_all(attrs={ \"class\" : \"row vert-align-middle color-charcoal hover-bg-blue-xlight padding-vert-small padding-horz-medium nowrap\" })\n",
    "    for i in providerList:\n",
    "      try:\n",
    "        linkProviders = [str(i.text.strip()), str(i.get(\"href\"))]\n",
    "        writer.writerow(linkProviders)\n",
    "        print(linkProviders)\n",
    "      except:\n",
    "        print(\"Error\")\n",
    "      \n",
    "# getInstitutions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get provider with their links\n",
    "\n",
    "def getProvider():\n",
    "  with open(\"./data/providers.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Name\", \"Link\"])\n",
    "    providerURL = \"https://www.classcentral.com/providers\"\n",
    "    providerPage = requests.get(providerURL, headers=HEADERS)\n",
    "\n",
    "    soup = bs(providerPage.content, \"lxml\")\n",
    "    providerList = soup.find_all(attrs={ \"class\" : \"row nowrap vert-align-middle text-1 hover-bg-gray-xlight hover-no-underline weight-semi color-charcoal padding-vert-medium padding-horz-small\" })\n",
    "    for i in providerList:\n",
    "      try:\n",
    "        linkProviders = [str(i.text.strip()), str(i.get(\"href\"))]\n",
    "        writer.writerow(linkProviders)\n",
    "        print(linkProviders)\n",
    "      except:\n",
    "        print(\"Error\")\n",
    "      \n",
    "# getProvider()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('universities.csv') as file_obj:\n",
    "  heading = next(file_obj)\n",
    "  universities = csv.reader(file_obj)\n",
    "  universities = list(universities)\n",
    "  for row in universities:\n",
    "    print(\"University Name: \"+str(row[0]))\n",
    "    print(\"University Name: \"+str(row[1]))\n",
    "    numberOfCourses =  str(row[0]).split(\" \")[-2]\n",
    "    Url = \"https://www.classcentral.com\"+str(row[1])\n",
    "    webpage = requests.get(str(Url), headers=HEADERS)\n",
    "    time.sleep(2)\n",
    "    soup = bs(webpage.content, \"lxml\")\n",
    "    # numberOfCourses = soup.findAll(attrs={'class':'hidden small-up-inline-block'})\n",
    "    # numberOfCourses = str(numberOfCourses[0].text.strip())\n",
    "    print(\"Number of courses available: \"+numberOfCourses+\" courses\")\n",
    "    numberOfCourses = numsberOfCourses.split(\" \")[-1]\n",
    "    numberOfPages = int(numberOfCourses)//15\n",
    "    print(\"Number of pages: \"+str(numberOfPages) + \" pages\")\n",
    "\n",
    "    with open('countries1.csv', 'w', encoding='UTF8', newline='') as f:\n",
    "      writer = csv.writer(f)\n",
    "      header = [\"Course Name\", \"Course Description\", \"Course Link\", \"Course Provider\", \"Course Duration\", \"Course Pricing\"]\n",
    "      writer.writerow(header)\n",
    "      i = 1\n",
    "      while i <= numberOfPages:\n",
    "        start = time.time()\n",
    "        webpage = requests.get(str(Url+\"?page=\"+str(i)), headers=HEADERS)\n",
    "        time.sleep(1)\n",
    "        soup = bs(webpage.content, \"lxml\") \n",
    "        courseName = soup.findAll(attrs={'class':'text-1 weight-semi line-tight margin-bottom-xxsmall'})\n",
    "        courseDescription = soup.findAll(attrs={'class':'color-charcoal block hover-no-underline break-word'})\n",
    "        # courseLink = soup.findAll(attrs={'class':'block hover-no-underline'})\n",
    "        courseProvider = soup.findAll(attrs={'class':'hover-underline color-charcoal text-3 margin-left-small line-tight', \"aria-label\":\"Provider\"})\n",
    "        courseDuration = soup.findAll(attrs={'class':'text-3 margin-left-small line-tight', \"aria-label\":\"Workload and duration\"})\n",
    "        coursePricing = soup.findAll(attrs={'class':'text-3 margin-left-small line-tight', \"aria-label\":\"Pricing\"})\n",
    "        if len(courseName) >= 10:\n",
    "          for m in range(len(courseName)): \n",
    "            try:\n",
    "              result = [courseName[m].text.strip(), courseDescription[m].text.strip(),str(courseDescription[m].get(\"href\")), courseProvider[m].text.strip(), courseDuration[m].text.strip(), coursePricing[m].text.strip()]\n",
    "              writer.writerow(result)\n",
    "            except:\n",
    "              print(\"List index out of range\")\n",
    "              pass\n",
    "          end = time.time()\n",
    "          print(\"Found \" + str(len(courseName)) + \" courses in page \"+ str(i)+ \"   \" + str(numberOfPages-i) + \" pages left\" + \"   \" + str(int(end-start)) + \" seconds\" + \"    \" + str(((numberOfPages-i)/numberOfPages)*100) + \" %\")\n",
    "          i += 1\n",
    "          \n",
    "          \n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x1995937e4a0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pymongo\n",
    "\n",
    "clustering = pymongo.MongoClient(\"mongodb+srv://adithyask:adithyask@courses.9v6zz7i.mongodb.net/test\")\n",
    "db = clustering[\"courses\"]\n",
    "collection = db[\"providers\"]\n",
    "\n",
    "document = [{\"name\": \"hello\" },{ \"name\": \"world\" }]\n",
    "\n",
    "collection.insert_many(document)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
